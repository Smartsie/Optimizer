{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Optimizer v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smartsie/Optimizer/blob/master/Optimizer_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMbIbgUgt5OD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b92de2b8-a4bf-4658-a9d5-e4cd57ff31c5"
      },
      "source": [
        "\"\"\" \n",
        "Optim package - T Martin 10 May 2020\n",
        "This code if for multivariate optimizer using surrogate response surface created by several ML models\n",
        "The next target point to study is either based on minimum point found, either by using a surrogate if r2 value of \n",
        "a model is above a certain threshold\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nOptim package - T Martin 10 May 2020\\nThis code if for multivariate optimizer using surrogate response surface created by several ML models\\nThe next target point to study is either based on minimum point found, either by using a surrogate if r2 value of \\na model is above a certain threshold\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RifTwkU2SJ00",
        "colab_type": "text"
      },
      "source": [
        "# **Functionnalities to be added**\n",
        "1.   Models should be listed in a dictionnary. Each model is defined by it's function or class with train, predict and score \n",
        "2.   During fitting, we will score all models. The highest score will then be used for the prediction\n",
        "3. This could be done by doing a voting of top 3 best models with a 3,2,1 weight for instance\n",
        "4. Models accuracy will evolve with time (DOF)\n",
        "5. Evaluation of models done on X-validation\n",
        "6. Add early stop \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pk5cxvmx3jK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "82828c35-4c41-4df9-8f0c-1b79bfaf5352"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNIu79cgt5OJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CaMepkAt5OT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05a41372-99fb-45e6-e761-b80d1d045099"
      },
      "source": [
        "import plotly as py\n",
        "from keras.layers import Dense\n",
        "import lightgbm\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2qurBjKt5OW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "kernel = DotProduct() + WhiteKernel()\n",
        "model = GaussianProcessRegressor(random_state=0)\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqDIKPnat5OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If we want to export in html in a separate browser\n",
        "import plotly.io as pio\n",
        "#pio.renderers.default = \"browser\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZKDLmncYAtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Japan_map():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  df=pd.read_csv('/content/drive/My Drive/Colab Data/Japan_XYZ_data.txt',header=None,delimiter=r\"\\s+\")\n",
        "  df.columns=['x0','x1','z']\n",
        "  # Flip the data in z so that Mt Fuji is minimum\n",
        "  df['z']=-df['z']\n",
        "  # Resample the Dataframe to speed things up\n",
        "  # N=10000 --> we keep only 10000 points\n",
        "  N=500000\n",
        "  step=int(len(df)/N)\n",
        "  DF=df[::step]\n",
        "\n",
        "  print('Theoretical Minimum:')\n",
        "  print(DF.iloc[np.argmin(DF.z)])\n",
        "  minx0=DF.iloc[np.argmin(DF.z)][0]\n",
        "  minx1=DF.iloc[np.argmin(DF.z)][1]\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2evbINqJWFOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_f(vector):\n",
        "  x1std=DF['x0'].std()\n",
        "  x2std=DF['x1'].std()\n",
        "  mask1=np.abs(DF['x0']-vector[0])<x1std/4\n",
        "  mask2=np.abs(DF['x1']-vector[1])<x2std/4\n",
        "  a=DF[mask1&mask2]\n",
        "  result=a['z'].min()\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErTw-ZqGt5Ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define function to minimize\n",
        "def funct(x):\n",
        "    x1=x[0]\n",
        "    x2=x[1]\n",
        "    #f=x1*x1+x1*x2+2*np.sin((x1+x2)*2)+4*np.cos(x2*2)\n",
        "    f=x1*x1+x2*x2-x1*x2+20*np.sin(x1-x2)-8*np.cos(x2*2)\n",
        "    f=(x1-3)*(x1-3)+(x2-1)*(x2-1)\n",
        "    #f=3*x1*x1-2*x2+5*x1/x2\n",
        "    ## Lévi function\n",
        "    #f=(np.sin(3*3.1415*x1))**2+(x1-1)**2*(1+(np.sin(3*3.1415*x2))**2)+(x2-1)**2*(1+(np.sin(2*3.1415*x2))**2)\n",
        "    # For Japan map f=eval_f(x)\n",
        "    return f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtD0pAztjNVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the desX_ign space as center point with radius\n",
        "x0range=[-5,5]\n",
        "x1range=[-5,5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1fp4qHbt5Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def Optimtm(plot_steps=True):\n",
        "  # for japan x0range=[DF.x0.min(),DF.x0.max()]\n",
        "  # x1range=[DF.x1.min(),DF.x1.max()]\n",
        "  # This function adds the points to the matrix\n",
        "  # The matrix is a dataframe\n",
        "  def add_matrix(X,points):\n",
        "      df=points\n",
        "      for i in range(len(df)):\n",
        "          variables=df.iloc[i]\n",
        "          variables['z']=funct(variables)\n",
        "          X=X.append(variables)\n",
        "      return X\n",
        "  # Define function providing N randoms points in the restraied domain \n",
        "  def next_point(current_space,n=5):\n",
        "      next_space=current_space\n",
        "      pt=pd.DataFrame()\n",
        "      for i in range(n):\n",
        "          vecteur=current_space['Center']\n",
        "          Radius=current_space['Radius']\n",
        "          new_vec=vecteur+Radius*np.random.choice((-1,1),size=len(Radius))*(np.random.random(len(Radius)))\n",
        "          for j in range(len(new_vec)):\n",
        "              if new_vec[j]<space.iloc[j]['Center']-space.iloc[j]['Radius']:\n",
        "                  new_vec[j]=space.iloc[j]['Center']-space.iloc[j]['Radius']\n",
        "              if new_vec[j]>space.iloc[j]['Center']+space.iloc[j]['Radius']:\n",
        "                  new_vec[j]=space.iloc[j]['Center']+space.iloc[j]['Radius']                              \n",
        "          pt['n'+str(i)]=new_vec\n",
        "      pt=pt.T\n",
        "      pt.columns=X.drop('z',axis=1).columns\n",
        "      #next_space['Radius']=next_space['Radius']*epsilon\n",
        "      return pt\n",
        "  def training_loop(X,domain,AI=False,n=5,epsilon=0.95):\n",
        "      df=next_point(domain,n)\n",
        "      Matrix=add_matrix(X,df)\n",
        "      x=Matrix.drop('z',axis=1).values\n",
        "      y=Matrix['z'].values\n",
        "      if AI==True:\n",
        "          # Need to do a CV split with Train test split\n",
        "          models={LinearRegression(), lightgbm.LGBMRegressor(),GaussianProcessRegressor(random_state=0)}\n",
        "          # Additional models: MLPRegressor(hidden_layer_sizes=(5,3),max_iter=300, verbose=False,learning_rate_init=0.05),\n",
        "          # XGBRegressor(objective ='reg:squarederror')\n",
        "          X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.8,shuffle=True)\n",
        "          r2max=-10\n",
        "          best_model=LinearRegression()\n",
        "          for model_loop in models:\n",
        "            model_loop.fit(X_train,y_train)\n",
        "            r2=model_loop.score(X_test,y_test)\n",
        "            if r2>r2max:\n",
        "              r2max=r2\n",
        "              best_model=model_loop\n",
        "          model=best_model\n",
        "          # Retrain the model with all data\n",
        "          model.fit(x,y)\n",
        "          # Predict and find the minimum in one shot\n",
        "          Prediction=model.predict(srf_x.values)\n",
        "          lowest_value=np.min(Prediction)\n",
        "          minimum=srf.iloc[np.argmin(Prediction)]    \n",
        "          # Evaluate at minimum\n",
        "          lowest_value=funct(minimum.values)    \n",
        "          if r2max<0.7:\n",
        "            #print('R2 insufficient %0.2f'%r2max)\n",
        "            theor_min=np.argmin(X.z.values)\n",
        "            lowest_value=np.min(X.z.values)\n",
        "            minimum=X.iloc[theor_min]\n",
        "          else:\n",
        "              print(\"Model found !!!!!!!!! with r2=%0.2f\"%r2max)\n",
        "      else:\n",
        "          theor_min=np.argmin(X.z.values)\n",
        "          lowest_value=np.min(X.z.values)\n",
        "          minimum=X.iloc[theor_min]\n",
        "      minimum=minimum.drop('z')\n",
        "      # New space should be centered around this minimum\n",
        "      domain['Center']=(minimum.values*0.5+domain.Center*0.5)\n",
        "      domain['Radius']=domain['Radius']*epsilon\n",
        "      return Matrix,domain,lowest_value\n",
        "  space=pd.DataFrame(columns=['Center','Radius'])\n",
        "  space.loc[0]=[np.mean(x0range),0.5*(x0range[1]-x0range[0])]\n",
        "  space.loc[1]=[np.mean(x1range),0.5*(x1range[1]-x1range[0])]\n",
        "  # Initialize X matrix\n",
        "  X=pd.DataFrame()\n",
        "  for i in range(len(space)):\n",
        "      X['x'+str(i)]=0\n",
        "  X['z']=0\n",
        "  # Fill X with 5 points\n",
        "  X['x0']=[x0range[0],x0range[0],x0range[1],x0range[1],(x0range[0]+x0range[1])/2,(x0range[0]+x0range[1])/2,(x0range[0]+x0range[1])/2,x0range[0],x0range[1]]\n",
        "  X['x1']=[x1range[0],x1range[1],x1range[0],x1range[1],(x1range[0]+x1range[1])/2,x1range[0],x1range[1],(x1range[0]+x1range[1])/2,(x1range[0]+x1range[1])/2]\n",
        "  for i in range(len(X)):\n",
        "      variables=X.iloc[i]\n",
        "      #variables['target']=funct(variables[['x0','x1']].values)\n",
        "      tgt=funct(variables.values)\n",
        "      X.iloc[i]['z']=tgt\n",
        "\n",
        "  # Initialize domain\n",
        "  domain=space.copy()\n",
        "\n",
        "  # Initialize Evaluation surface\n",
        "  N=100\n",
        "  srf=[]\n",
        "  loc=0\n",
        "  for i in np.linspace(x0range[0],x0range[1],N):\n",
        "    for j in np.linspace(x1range[0],x1range[1],N):\n",
        "      vector=[i,j,funct([i,j])]\n",
        "      srf.append(vector)\n",
        "  srf=pd.DataFrame(srf,columns=['x0','x1','z'])\n",
        "  # for japan srf=DF\n",
        "  srf_x=srf.drop(['z'],axis=1)\n",
        "\n",
        "\n",
        "  plot_srf=False\n",
        "  if plot_srf==True:\n",
        "    fig = px.scatter_3d(srf, x='x0', y='x1', z='z',color='z')\n",
        "    fig.show()\n",
        "  print(\"Minimum : \",np.min(srf.z))\n",
        "  print(srf.iloc[np.argmin(srf.z)])\n",
        "  minx0=srf.iloc[np.argmin(srf.z)][0]\n",
        "  minx1=srf.iloc[np.argmin(srf.z)][1]\n",
        "\n",
        "  # Run the training loop\n",
        "  N=20\n",
        "  Max_points=20\n",
        "  point_amount=Max_points\n",
        "  Dom=[] #pd.DataFrame(columns=['x0 C','x0 R','x1 C','x1 R'])]\n",
        "  for i in range(N):\n",
        "      # Point amound should decrease. At the beginning, it should be 10. At the end, 2.\n",
        "      #point_amount=np.int((Max_points-3)-(Max_points-3)*i/N)+3\n",
        "\n",
        "      X,domain,minimum=training_loop(X,domain,AI=True,n=point_amount,epsilon=0.8)\n",
        "      #print(i,minimum)\n",
        "      #Dom=np.append(Dom,[i,domain.loc[0].values])\n",
        "      vect=[i, domain.loc[0].values[0],domain.loc[0].values[1],domain.loc[1].values[0],domain.loc[1].values[1]]\n",
        "      Dom.append(vect)\n",
        "      if plot_steps==True:\n",
        "        plt.scatter(X['x0'],X['x1'],color='blue')\n",
        "        plt.scatter(Dom[-1][1],  Dom[-1][3],color='green')\n",
        "        plt.scatter(minx0,minx1,color='red')\n",
        "        plt.title(\"Loop \"+str(i)+ \"Minimum = %0.1f\"%minimum)\n",
        "        plt.show()\n",
        "  Dom=pd.DataFrame(Dom,columns=['idx','x0 C','x0 R','x1 C','x1 R'])\n",
        "  min_found=np.min(X.z.values)\n",
        "  best_point=X.iloc[np.argmin(X.z.values)]\n",
        "  return X,min_found, best_point"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vWsRemGumKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "79a273f0-876c-4003-93cd-e5f2534b78fd"
      },
      "source": [
        "X,min_found, best_points=Optimtm(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum :  0.002040608101214206\n",
            "x0    2.979798\n",
            "x1    0.959596\n",
            "z     0.002041\n",
            "Name: 7959, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhI0VqlOsseA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b5940ac6-83e4-42a8-ee46-c083d73a9d8b"
      },
      "source": [
        "# Print Minimum found\n",
        "min=np.min(X.z.values)\n",
        "print(\"Minimum found:\")\n",
        "print(X.iloc[np.argmin(X.z.values)])\n",
        "#print(\"Theoretical Minimum : \")\n",
        "#print(srf.iloc[np.argmin(srf.z)])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum found:\n",
            "x0    2.993185\n",
            "x1    1.000014\n",
            "z     0.000046\n",
            "Name: n2, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWYcV_CQt5PP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_convergence():\n",
        "  plt.plot(Dom.idx,Dom['x0 C'],color='red')\n",
        "  plt.plot(Dom.idx,Dom['x0 C']+Dom['x0 R'],color='blue')\n",
        "  plt.plot(Dom.idx,Dom['x0 C']-Dom['x0 R'],color='blue')\n",
        "  plt.title('X0')\n",
        "  plt.show()\n",
        "  plt.plot(Dom.idx,Dom['x1 C'],color='red')\n",
        "  plt.plot(Dom.idx,Dom['x1 C']+Dom['x1 R'],color='blue')\n",
        "  plt.plot(Dom.idx,Dom['x1 C']-Dom['x1 R'],color='blue')\n",
        "  plt.title('X1')\n",
        "  plt.show()\n",
        "  #plt.plot(Dom['x0 C'],Dom['x1 C'],color='red')\n",
        "  plt.plot(Dom['x0 C'],Dom['x1 C'])\n",
        "  plt.ylabel('X1')\n",
        "  plt.xlabel('X0')\n",
        "  plt.show()\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49gX4bOW2iE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3ab2d5d4-276b-4158-e494-b6efbeb6e3c1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-22baa3ecb9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-1730f4a661ca>\u001b[0m in \u001b[0;36mplot_convergence\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0 C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0 C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0 R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0 C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mDom\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x0 R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dom' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOmiDkP81R6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Hypertopt package\n",
        "from hyperopt import hp, tpe, Trials, fmin,STATUS_OK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rZCgoQY2gio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcmm7O0a1SEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "space = {\n",
        "    'x0': hp.uniform('x0', x0range[0], x0range[1]),\n",
        "    'x1': hp.uniform('x1', x1range[0], x1range[1])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34FsL-PU39YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(params):\n",
        "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Tuning\"\"\"\n",
        "    x_vector=[params[i] for i in params]\n",
        "    # Loss must be minimized\n",
        "    loss = funct(x_vector)\n",
        "    # Dictionary with information for evaluation\n",
        "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPbTvvga1SMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69e1924b-2c99-46a2-8e42-4d834f55c9de"
      },
      "source": [
        "# Algorithm\n",
        "tpe_algorithm = tpe.suggest\n",
        "# Trials object to track progress\n",
        "bayes_trials = Trials()\n",
        "MAX_EVALS = 49\n",
        "\n",
        "# Optimize\n",
        "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
        "            max_evals = MAX_EVALS, trials = bayes_trials)\n",
        "print(objective(best))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0388105332515103, -1.0847119002187977]\n",
            "24.912539651073132\n",
            "[-9.306897028107548, 3.795015123459489]\n",
            "124.0469734840585\n",
            "[9.46453598969714, -7.99763114694251]\n",
            "217.2409564891852\n",
            "[0.7159373239645994, -1.0208328102955928]\n",
            "25.639966130709535\n",
            "[-6.775545860596875, -3.547896728847551]\n",
            "30.67480557588163\n",
            "[6.483686946398123, 8.971694161118421]\n",
            "47.26496439348818\n",
            "[-7.8078714922618015, 5.782287405764478]\n",
            "118.15304809096013\n",
            "[-3.0514326782226897, -6.909439655830378]\n",
            "20.330688390804905\n",
            "[7.845769605354821, 0.13548725212782742]\n",
            "72.59723192519344\n",
            "[6.373191964608097, 9.873761134771176]\n",
            "77.22206955184286\n",
            "[3.587527100697983, -1.2082127778868408]\n",
            "4.7211672332023715\n",
            "[8.666622698728585, -9.43697311097248]\n",
            "224.3823300099965\n",
            "[-6.789915787398599, 3.8196892101601243]\n",
            "103.45335148098114\n",
            "[-0.5762709124863985, -0.5333033101077245]\n",
            "-4.414699314867706\n",
            "[9.045193711885766, -1.5815873396785474]\n",
            "87.96558757278352\n",
            "[-9.231374415350928, 5.841572490730334]\n",
            "156.32687815699424\n",
            "[5.27924594554721, -0.6794053776176749]\n",
            "23.858223385506555\n",
            "[-6.366508836340974, -6.724970160909736]\n",
            "44.884585757120966\n",
            "[-6.504759795673294, -9.966373647983804]\n",
            "66.77181292491454\n",
            "[5.690192389957092, -6.1294581737870875]\n",
            "83.61678263940888\n",
            "[2.9919142622947987, -4.117123088229552]\n",
            "55.89217529511308\n",
            "[-1.8313525669250617, -3.490191951267497]\n",
            "22.932903166539994\n",
            "[-3.084861550982916, 1.233797384367251]\n",
            "39.565073291914985\n",
            "[3.482254867920486, 1.8525666720936647]\n",
            "35.83527273345772\n",
            "[-0.6204764528317711, 3.1778202050051623]\n",
            "16.686478981645095\n",
            "[2.631533675514437, -2.4542856962503725]\n",
            "-0.7740155911824766\n",
            "[1.9540190856394277, -4.706621801951328]\n",
            "50.537903219698684\n",
            "[-4.122321717586092, -3.1766816986992934]\n",
            "-10.208202310010993\n",
            "[-4.715227089477301, -5.449922457245352]\n",
            "40.409287889457175\n",
            "[-0.42691240192216107, 0.9845147216944188]\n",
            "-15.072404083519634\n",
            "[-4.733324331140816, 5.781366528940687]\n",
            "96.62747087185849\n",
            "[-1.917860230070069, 1.4811658733667805]\n",
            "21.67650366892718\n",
            "[-5.030274631172319, -8.200251050861375]\n",
            "56.8876859825003\n",
            "[-9.502691798044843, -2.517051697569089]\n",
            "57.26652081332738\n",
            "[1.3195011705070794, 7.028811752812109]\n",
            "52.09287849594193\n",
            "[-3.5740925472480596, 3.2053034322209455]\n",
            "17.047082794064774\n",
            "[0.6132482125327174, 0.4807025931159471]\n",
            "-1.6234308993764892\n",
            "[-7.924521832786141, -2.431911109274798]\n",
            "62.44881572046011\n",
            "[-1.099002281256829, -8.146959649451922]\n",
            "79.1401515742739\n",
            "[-3.8495186926167935, 8.357412012078187]\n",
            "128.14827535580628\n",
            "[-2.1867683617462115, 4.133194732236672]\n",
            "33.37473564283285\n",
            "[0.10392756317739682, 0.47371386207932]\n",
            "-11.712537787063255\n",
            "[4.830767823778537, 4.857149475794616]\n",
            "30.603931471265334\n",
            "[0.47560248904641456, 2.6906710052352807]\n",
            "-14.765843991589652\n",
            "[4.365738943840644, 2.448794722956419]\n",
            "31.70605741045878\n",
            "[1.796673055375216, 8.193189178248884]\n",
            "59.60267992168413\n",
            "[9.966522531141797, 4.793922867320072]\n",
            "64.50921974054006\n",
            "[0.8213757612416313, -1.5681476825460985]\n",
            "26.0846978963367\n",
            "[7.779486925929651, 6.7318758093326725]\n",
            "65.8033962346569\n",
            "100%|██████████| 49/49 [00:00<00:00, 78.50it/s, best loss: -15.072404083519634]\n",
            "[-0.42691240192216107, 0.9845147216944188] -15.072404083519634\n",
            "{'loss': -15.072404083519634, 'params': {'x0': -0.42691240192216107, 'x1': 0.9845147216944188}, 'status': 'ok'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paCmd1Z45BI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97e23a6e-513c-499e-c388-cb62de27aa7b"
      },
      "source": [
        "bayes_trials"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hyperopt.base.Trials at 0x7f1653828e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifiKD18k91r6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fa565d1-7a79-449b-d73b-53e591130f52"
      },
      "source": [
        "# Run the experiments\n",
        "X,min_found, best_points=Optimtm(plot_steps=False)\n",
        "print(\"Minimum found:\",min_found, \" at \",best_points)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum :  -25.72524324258832\n",
            "x0    -1.313131\n",
            "x1     0.101010\n",
            "z    -25.725243\n",
            "Name: 4350, dtype: float64\n",
            "R2 insufficient -0.46\n",
            "R2 insufficient -0.03\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient -0.24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient -0.46\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.12\n",
            "R2 insufficient -0.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.08\n",
            "R2 insufficient -0.02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient -0.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient -0.22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.32\n",
            "R2 insufficient -0.22\n",
            "R2 insufficient 0.38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient 0.36\n",
            "R2 insufficient -0.09\n",
            "R2 insufficient 0.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning:\n",
            "\n",
            "Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:614: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "R2 insufficient -0.11\n",
            "Minimum found: -21.835512802509268  at  x0    -0.620433\n",
            "x1     0.288876\n",
            "z    -21.835513\n",
            "Name: n0, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udFar6EE91pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEi22ite5BDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}